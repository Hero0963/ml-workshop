{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88811bab",
   "metadata": {},
   "source": [
    "其实就是去基线的Actor_Critic算法\n",
    "\n",
    "Actor_Critic算法中使用critic模型估计state的价值,也就是估计Q\n",
    "\n",
    "这样估计出来的Q是没有去基线的,而要去基线也非常简单,target-value即可\n",
    "\n",
    "换个角度来想这个问题,target是根据next_state估计出来的,value是根据state估计出来的\n",
    "\n",
    "所以两者的差值可以视为action好坏的衡量,这可以作为actor模型训练的依据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f713c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "        \n",
    "        #没坚持到最后,扣分\n",
    "        if over and self.step_n < 200:\n",
    "            reward = -1000\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe8e8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "   (5): Softmax(dim=1)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#演员模型,计算每个动作的概率\n",
    "model_actor = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "#评委模型,计算每个状态的价值\n",
    "model_critic = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_critic_delay = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_critic_delay.load_state_dict(model_critic.state_dict())\n",
    "\n",
    "model_actor, model_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c83482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\it_project\\github_sync\\ml-workshop\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2820\\2154798901.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  state = torch.FloatTensor(state).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-990.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    state = []\n",
    "    action = []\n",
    "    reward = []\n",
    "    next_state = []\n",
    "    over = []\n",
    "\n",
    "    s = env.reset()\n",
    "    o = False\n",
    "    while not o:\n",
    "        #根据概率采样\n",
    "        prob = model_actor(torch.FloatTensor(s).reshape(1, 4))[0].tolist()\n",
    "        a = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        ns, r, o = env.step(a)\n",
    "\n",
    "        state.append(s)\n",
    "        action.append(a)\n",
    "        reward.append(r)\n",
    "        next_state.append(ns)\n",
    "        over.append(o)\n",
    "\n",
    "        s = ns\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    state = torch.FloatTensor(state).reshape(-1, 4)\n",
    "    action = torch.LongTensor(action).reshape(-1, 1)\n",
    "    reward = torch.FloatTensor(reward).reshape(-1, 1)\n",
    "    next_state = torch.FloatTensor(next_state).reshape(-1, 4)\n",
    "    over = torch.LongTensor(over).reshape(-1, 1)\n",
    "\n",
    "    return state, action, reward, next_state, over, reward.sum().item()\n",
    "\n",
    "\n",
    "state, action, reward, next_state, over, reward_sum = play()\n",
    "\n",
    "reward_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae98ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_actor = torch.optim.Adam(model_actor.parameters(), lr=1e-3)\n",
    "optimizer_critic = torch.optim.Adam(model_critic.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "def requires_grad(model, value):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6afd385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_critic(state, reward, next_state, over):\n",
    "    requires_grad(model_actor, False)\n",
    "    requires_grad(model_critic, True)\n",
    "\n",
    "    #计算values和targets\n",
    "    value = model_critic(state)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target = model_critic_delay(next_state)\n",
    "    target = target * 0.99 * (1 - over) + reward\n",
    "\n",
    "    #时序差分误差,也就是tdloss\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_critic.step()\n",
    "    optimizer_critic.zero_grad()\n",
    "\n",
    "    #减去value相当于去基线\n",
    "    return (target - value).detach()\n",
    "\n",
    "\n",
    "value = train_critic(state, reward, next_state, over)\n",
    "\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9b7e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-72.2009048461914"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_actor(state, action, value):\n",
    "    requires_grad(model_actor, True)\n",
    "    requires_grad(model_critic, False)\n",
    "\n",
    "    #重新计算动作的概率\n",
    "    prob = model_actor(state)\n",
    "    prob = prob.gather(dim=1, index=action)\n",
    "\n",
    "    #根据策略梯度算法的导函数实现\n",
    "    #函数中的Q(state,action),这里使用critic模型估算\n",
    "    prob = (prob + 1e-8).log() * value\n",
    "    loss = -prob.mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_actor.step()\n",
    "    optimizer_actor.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_actor(state, action, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d64f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -34.89494705200195 -977.15\n",
      "100 0.9660327434539795 -112.55\n",
      "200 -2.1864757537841797 -5.75\n",
      "300 -1.0637701749801636 200.0\n",
      "400 -0.7788228392601013 200.0\n",
      "500 -0.12250345945358276 200.0\n",
      "600 -0.37511932849884033 200.0\n",
      "700 -0.4166830778121948 200.0\n",
      "800 -0.9411654472351074 200.0\n",
      "900 -0.13936306536197662 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model_actor.train()\n",
    "    model_critic.train()\n",
    "\n",
    "    #训练N局\n",
    "    for epoch in range(1000):\n",
    "\n",
    "        #一个epoch最少玩N步\n",
    "        steps = 0\n",
    "        while steps < 200:\n",
    "            state, action, reward, next_state, over, _ = play()\n",
    "            steps += len(state)\n",
    "\n",
    "            #训练两个模型\n",
    "            value = train_critic(state, reward, next_state, over)\n",
    "            loss = train_actor(state, action, value)\n",
    "\n",
    "        #复制参数\n",
    "        for param, param_delay in zip(model_critic.parameters(),\n",
    "                                      model_critic_delay.parameters()):\n",
    "            value = param_delay.data * 0.7 + param.data * 0.3\n",
    "            param_delay.data.copy_(value)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, loss, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82778ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
