{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa150a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "        \n",
    "        #没坚持到最后,扣分\n",
    "        if over and self.step_n < 200:\n",
    "            reward = -1000\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d33ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "   (5): Softmax(dim=1)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "* 作用: 這裡定義了兩個神經網路，這是與前一個 Notebook 最大的不同。\n",
    "* `model_action`: 策略網路 (Policy Network)。和之前一樣，它的作用是輸入狀態，輸出每個動作的機率。\n",
    "* `model_baseline`: 價值網路 (Value\n",
    "    Network)。這是一個全新的模型，它的作用是輸入狀態，輸出一個單一的數值，這個數值代表對當前狀態的價值評估\n",
    "    (Value)。它試圖預測從當前狀態開始，預期能獲得多少未來總獎勵。\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "#定义模型,计算每个动作的概率\n",
    "model_action = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "#基线模型,评估state的价值\n",
    "model_baseline = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_action, model_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfabd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-988.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    state = []\n",
    "    action = []\n",
    "    reward = []\n",
    "\n",
    "    s = env.reset()\n",
    "    o = False\n",
    "    while not o:\n",
    "        #根据概率采样\n",
    "        prob = model_action(torch.FloatTensor(s).reshape(1, 4))[0].tolist()\n",
    "        a = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        ns, r, o = env.step(a)\n",
    "\n",
    "        state.append(s)\n",
    "        action.append(a)\n",
    "        reward.append(r)\n",
    "\n",
    "        s = ns\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    state = torch.FloatTensor(state).reshape(-1, 4)\n",
    "    action = torch.LongTensor(action).reshape(-1, 1)\n",
    "    reward = torch.FloatTensor(reward).reshape(-1, 1)\n",
    "\n",
    "    return state, action, reward, reward.sum().item()\n",
    "\n",
    "\n",
    "state, action, reward, reward_sum = play()\n",
    "\n",
    "reward_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f14a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * 作用: 因為有兩個模型，所以需要建立兩個獨立的優化器來分別更新它們的權重。\n",
    "'''\n",
    "\n",
    "optimizer_action = torch.optim.Adam(model_action.parameters(), lr=5e-3)\n",
    "optimizer_baseline = torch.optim.Adam(model_baseline.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a3c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "這個函式與 01_reinforce.ipynb 中的價值計算邏輯完全相同，都是用蒙地卡羅法計算從每一步開始的未來總折扣獎勵。我們仍然稱這個為 value。\n",
    "'''\n",
    "\n",
    "def get_value(reward):\n",
    "    #计算当前state的价值,其实就是Q(state,action),这里是用蒙特卡洛法估计的\n",
    "    value = []\n",
    "    for i in range(len(reward)):\n",
    "        s = 0\n",
    "        for j in range(i, len(reward)):\n",
    "            s += reward[j] * 0.99**(j - i)\n",
    "        value.append(s)\n",
    "\n",
    "    return torch.FloatTensor(value).reshape(-1, 1)\n",
    "\n",
    "\n",
    "value = get_value(reward)\n",
    "\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f67c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "* 作用: 專門用來訓練 model_baseline (價值網路)。\n",
    "* 核心邏輯:\n",
    "    1. baseline = model_baseline(state): 將遊戲中實際經過的狀態 state 輸入價值網路，得到模型對這些狀態的價值預測 baseline。\n",
    "    2. loss = mse_loss(baseline, value): 計算均方誤差 (MSE)。這裡的 value 是我們用蒙地卡羅法算出的「真實」未來總獎勵。所以，這個 loss\n",
    "        的目標就是讓 model_baseline 的預測越來越接近「真實」的價值。\n",
    "    3. `return baseline.detach()`: 訓練完後，返回不帶梯度的 baseline 值。我們在下一步訓練策略網路時只需要這個數值，而不需要它的梯度。\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#训练baseline模型\n",
    "def train_baseline(state, value):\n",
    "    baseline = model_baseline(state)\n",
    "\n",
    "    loss = torch.nn.functional.mse_loss(baseline, value)\n",
    "    loss.backward()\n",
    "    optimizer_baseline.step()\n",
    "    optimizer_baseline.zero_grad()\n",
    "\n",
    "    return baseline.detach()\n",
    "\n",
    "\n",
    "baseline = train_baseline(state, value)\n",
    "\n",
    "baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c226c6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-597.4337158203125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "* 作用: 訓練 model_action (策略網路)。\n",
    "* 核心改動:\n",
    "    * 原本的 Loss 是 log(prob) * value。\n",
    "    * 現在的 Loss 變成了 log(prob) * (value - baseline)。\n",
    "    * value - baseline 這個量被稱為 Advantage (優勢)，寫作 $A(s, a)$。\n",
    "* 為什麼要這樣做？\n",
    "    * 假設在一局好遊戲中，所有 value 都是正的。在沒有 baseline\n",
    "        的情況下，所有動作都會被「鼓勵」。但事實上，這局好遊戲中可能有些動作是「比較差」的，只是運氣好。\n",
    "    * 引入 baseline 後，value - baseline 就變成了一個相對值。\n",
    "        * 如果 value > baseline (實際得到的比預期的好)，Advantage 為正，這個動作被鼓勵。\n",
    "        * 如果 value < baseline (實際得到的比預期的差)，Advantage 為負，這個動作被抑制 (即使 value 本身是正的！)。\n",
    "    * 這使得獎勵訊號更清晰，大大降低了訓練過程中的變異數，讓模型收斂得更穩定、更快速。\n",
    "'''\n",
    "\n",
    "#训练action模型\n",
    "def train_action(state, action, value, baseline):\n",
    "    #重新计算动作的概率\n",
    "    prob = model_action(state).gather(dim=1, index=action)\n",
    "\n",
    "    #求Q最大的导函数 -> partial value / partial action\n",
    "    #注意这里的Q使用前要去基线,这也是baseline模型存在的意义\n",
    "    prob = (prob + 1e-8).log() * (value - baseline)\n",
    "    for i in range(len(prob)):\n",
    "        prob[i] = prob[i] * 0.99**i\n",
    "    loss = -prob.mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_action.step()\n",
    "    optimizer_action.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_action(state, action, value, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d7ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -364.41156005859375 -965.55\n",
      "100 15.765361785888672 147.95\n",
      "200 15.636146545410156 200.0\n",
      "300 14.664276123046875 200.0\n",
      "400 15.47754192352295 147.05\n",
      "500 12.18871784210205 94.2\n",
      "600 13.042450904846191 200.0\n",
      "700 14.563920021057129 200.0\n",
      "800 12.581521034240723 200.0\n",
      "900 10.215791702270508 200.0\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "def train():\n",
    "    model_action.train()\n",
    "    model_baseline.train()\n",
    "\n",
    "    #训练N局\n",
    "    for epoch in range(1000):\n",
    "\n",
    "        #一个epoch最少玩N步\n",
    "        steps = 0\n",
    "        while steps < 200:\n",
    "\n",
    "            #玩一局游戏,得到数据\n",
    "            state, action, reward, _ = play()\n",
    "            steps += len(state)\n",
    "\n",
    "            #训练两个模型\n",
    "            value = get_value(reward)\n",
    "            baseline = train_baseline(state, value)\n",
    "            loss = train_action(state, action, value, baseline)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, loss, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834163bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
