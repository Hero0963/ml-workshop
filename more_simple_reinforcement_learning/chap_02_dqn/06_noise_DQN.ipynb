{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0591c9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1',\n",
    "                       render_mode='rgb_array',)\n",
    "\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    # step 就是進行了一次行動\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "        \n",
    "        #没坚持到最后,扣分\n",
    "        if over and self.step_n < 200:\n",
    "            reward = -1000\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5ef8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, sigma_init=0.017):\n",
    "        super().__init__()\n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        # 可训练的均值参数\n",
    "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.bias_mu   = nn.Parameter(torch.empty(out_features))\n",
    "        # 可训练的标准差参数\n",
    "        self.weight_sigma = nn.Parameter(torch.full((out_features, in_features), sigma_init))\n",
    "        self.bias_sigma   = nn.Parameter(torch.full((out_features,),       sigma_init))\n",
    "        self.reset_parameters()\n",
    "        # 注册用于采样的噪声张量\n",
    "        self.register_buffer('eps_weight', torch.zeros(out_features, in_features))\n",
    "        self.register_buffer('eps_bias',   torch.zeros(out_features))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # μ 初始化为小的均匀分布\n",
    "        bound = 1 / self.in_features**0.5\n",
    "        nn.init.uniform_(self.weight_mu, -bound, bound)\n",
    "        nn.init.uniform_(self.bias_mu,   -bound, bound)\n",
    "\n",
    "    def reset_noise(self):\n",
    "        # 采样新噪声\n",
    "        self.eps_weight.normal_()\n",
    "        self.eps_bias.normal_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            self.reset_noise()\n",
    "            weight = self.weight_mu + self.weight_sigma * self.eps_weight\n",
    "            bias   = self.bias_mu   + self.bias_sigma   * self.eps_bias\n",
    "        else:\n",
    "            # 测试时只用均值\n",
    "            weight = self.weight_mu\n",
    "            bias   = self.bias_mu\n",
    "\n",
    "        return nn.functional.linear(x, weight, bias)\n",
    "\n",
    "\n",
    "class DuelingNoisyQNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=64, output_dim=2):\n",
    "        super().__init__()\n",
    "        # 共享特征提取\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # 状态价值流（不加噪声也可以不过也可用 NoisyLinear）\n",
    "        self.value_head     = NoisyLinear(hidden_dim, 1)\n",
    "        # 优势流\n",
    "        self.advantage_head = NoisyLinear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared(x)\n",
    "        v = self.value_head(x)               # [batch, 1]\n",
    "        a = self.advantage_head(x)           # [batch, output_dim]\n",
    "        a_mean = a.mean(dim=-1, keepdim=True)\n",
    "        return v + (a - a_mean)              # [batch, output_dim]\n",
    "\n",
    "\n",
    "def clone_model(model: nn.Module) -> nn.Module:\n",
    "    clone = type(model)(*model._constructor_args) \\\n",
    "            if hasattr(model, \"_constructor_args\") else type(model)()\n",
    "    clone.load_state_dict(model.state_dict())\n",
    "    return clone\n",
    "\n",
    "\n",
    "# —— 实例化 —— #\n",
    "model       = DuelingNoisyQNetwork(input_dim=4, hidden_dim=64, output_dim=2)\n",
    "model_delay = clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb2678e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-991.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    data = []\n",
    "    reward_sum = 0\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    while not over:\n",
    "        #因为模型本身有随机性,所以这里不需要再随机动作\n",
    "        action = model(torch.FloatTensor(state).reshape(1, 4)).argmax().item()\n",
    "\n",
    "        next_state, reward, over = env.step(action)\n",
    "\n",
    "        data.append((state, action, reward, next_state, over))\n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    return data, reward_sum\n",
    "\n",
    "\n",
    "play()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85568c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,\n",
       " (array([ 0.025972  ,  0.02895751,  0.01997188, -0.04831583], dtype=float32),\n",
       "  0,\n",
       "  1.0,\n",
       "  array([ 0.02655115, -0.16644505,  0.01900557,  0.25060087], dtype=float32),\n",
       "  False))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据池\n",
    "class Pool:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pool = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pool)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.pool[i]\n",
    "\n",
    "    #更新动作池\n",
    "    def update(self):\n",
    "        #每次更新不少于N条新数据\n",
    "        old_len = len(self.pool)\n",
    "        while len(pool) - old_len < 200:\n",
    "            self.pool.extend(play()[0])\n",
    "\n",
    "        #只保留最新的N条数据\n",
    "        self.pool = self.pool[-2_0000:]\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def sample(self):\n",
    "        data = random.sample(self.pool, 64)\n",
    "\n",
    "        state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n",
    "        action = torch.LongTensor([i[1] for i in data]).reshape(-1, 1)\n",
    "        reward = torch.FloatTensor([i[2] for i in data]).reshape(-1, 1)\n",
    "        next_state = torch.FloatTensor([i[3] for i in data]).reshape(-1, 4)\n",
    "        over = torch.LongTensor([i[4] for i in data]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "pool = Pool()\n",
    "pool.update()\n",
    "pool.sample()\n",
    "\n",
    "len(pool), pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc7f75",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model_delay' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 49\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with score \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m訓練結束，最高分：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m，出現在 epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m，模型已存為 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m \u001b[43mtrain_with_save_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m, in \u001b[0;36mtrain_with_save_best_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m value \u001b[38;5;241m=\u001b[39m model(state)\u001b[38;5;241m.\u001b[39mgather(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, index\u001b[38;5;241m=\u001b[39maction)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 22\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_delay\u001b[49m(next_state)\n\u001b[0;32m     23\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m target \u001b[38;5;241m=\u001b[39m target \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.99\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m over) \u001b[38;5;241m+\u001b[39m reward\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'model_delay' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = DuelingNoisyQNetwork()\n",
    "model_delay = clone_model(model)\n",
    "pool = Pool()       # 重新開一個資料池\n",
    "pool.update()       # 重新收集資料\n",
    "\n",
    "def train_with_save_best_model():\n",
    "    global model_delay\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    best_score = float('-inf')  # 記錄最高分\n",
    "    best_epoch = -1             # 記錄最高分是哪個 epoch\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        pool.update()\n",
    "        for i in range(200):\n",
    "            state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "            value = model(state).gather(dim=1, index=action)\n",
    "            with torch.no_grad():\n",
    "                target = model_delay(next_state)\n",
    "            target = target.max(dim=1)[0].reshape(-1, 1)\n",
    "            target = target * 0.99 * (1 - over) + reward\n",
    "\n",
    "            loss = loss_fn(value, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # target network 更新\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model_delay = clone_model(model)\n",
    "            \n",
    "        # 每100回合評估一次\n",
    "        if epoch % 100 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(f\"Epoch {epoch}, Pool Size: {len(pool)}, Test Score: {test_result:.2f}\")\n",
    "            # 如果這次分數比以前高，就存下來\n",
    "            if test_result > best_score:\n",
    "                best_score = test_result\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "                print(f\"Best model saved at epoch {epoch} with score {test_result:.2f}\")\n",
    "\n",
    "    print(f\"訓練結束，最高分：{best_score:.2f}，出現在 epoch {best_epoch}，模型已存為 'best_model.pth'。\")\n",
    "\n",
    "\n",
    "train_with_save_best_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = DuelingNoisyQNetwork()\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_with_model(model, show=False):\n",
    "    data = []\n",
    "    reward_sum = 0\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    while not over:\n",
    "        action = model(torch.FloatTensor(state).reshape(1, 4)).argmax().item()\n",
    "        if random.random() < 0.1:\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        next_state, reward, over = env.step(action)\n",
    "\n",
    "        data.append((state, action, reward, next_state, over))\n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    return data, reward_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ba414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASAAAADMCAYAAADTcn7NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASaklEQVR4nO3da2xUVb/H8f9Mb1BKW1uktYc2cB55BMJNuRZeaKRSkRARXqghiAQhYiFclGgTLoKaEnyB4gP1jQJvEFNz0MABtLZQohQLxSZQoMHnaKhAW4HTK/Q662Qtz0yYdoCWtrM67feTbHb33mumq5uZX9dlT7dDKaUEACxw2vimAKARQACsIYAAWEMAAbCGAAJgDQEEwBoCCIA1BBAAawggANYQQAD6XgDt3LlThg4dKv369ZMpU6ZIQUGBraoA6EsB9PXXX8vatWtl06ZNcvbsWRk3bpykpqZKRUWFjeoAsMRh48OousUzadIk+de//mW2XS6XJCYmysqVK+W9997zd3UAWBLs72/Y2NgohYWFkp6e7tnndDolJSVF8vPzfT6moaHBLG46sG7duiWxsbHicDj8Um8A7afbNTU1NZKQkGDe3z0mgG7cuCEtLS0SFxfntV9vX7p0yedjMjIyZPPmzX6qIYCuUlpaKkOGDOk5AfQwdGtJjxm5VVVVSVJSkvnhIiMjrdYNQFvV1dVmWGXgwIFyP34PoEGDBklQUJCUl5d77dfb8fHxPh8TFhZmltZ0+BBAQM/1oCESv8+ChYaGyoQJEyQnJ8drTEdvJycn+7s6ACyy0gXT3alFixbJxIkTZfLkyfLJJ59IXV2dLF682EZ1APSlAHr55Zflr7/+ko0bN0pZWZmMHz9ejh492mZgGkDvZuU6oK4Y4IqKijKD0YwBAYH7HuWzYACsIYAAWEMAAbCGAAJgDQEEwBoCCIA1BBAAawggANYQQACsIYAAWEMAAbCGAAJgDQEEwBoCCIA1BBAAawggANYQQACsIYAAWEMAAbCGAAJgDQEEwBoCCIA1BBAAawggANYQQACsIYAAWEMAAbCGAAIQOAF04sQJmTNnjiQkJIjD4ZBvv/3W67hSSjZu3CiPPfaY9O/fX1JSUuTy5cteZW7duiULFiwwN62Pjo6WJUuWSG1tbed/GgC9O4Dq6upk3LhxsnPnTp/Ht23bJjt27JDPP/9cfvnlFxkwYICkpqZKfX29p4wOn+LiYsnOzpZDhw6ZUFu2bFnnfhIAgUd1gn74gQMHPNsul0vFx8erjz/+2LOvsrJShYWFqa+++spsX7hwwTzu9OnTnjJHjhxRDodDXb16tV3ft6qqyjyHXgPoedr7Hu3SMaDff/9dysrKTLfLLSoqSqZMmSL5+flmW691t2vixImeMrq80+k0LSZfGhoapLq62msBEPi6NIB0+GhxcXFe+/W2+5heDx482Ot4cHCwxMTEeMq0lpGRYYLMvSQmJnZltQFYEhCzYOnp6VJVVeVZSktLbVcJQE8LoPj4eLMuLy/32q+33cf0uqKiwut4c3OzmRlzl2ktLCzMzJjdvQAIfF0aQMOGDTMhkpOT49mnx2v02E5ycrLZ1uvKykopLCz0lMnNzRWXy2XGigD0HcEdfYC+Xue3337zGnguKioyYzhJSUmyevVq+fDDD2X48OEmkDZs2GCuGZo7d64pP3LkSHn++edl6dKlZqq+qalJVqxYIa+88oopB6AP6ej02rFjx8z0Wutl0aJFnqn4DRs2qLi4ODP9PmPGDFVSUuL1HDdv3lSvvvqqioiIUJGRkWrx4sWqpqamy6f4ANjR3veoQ/8jAUZ36/RsmB6QZjwICNz3aEDMggHonQggANYQQACsIYAAWEMAAbCGAAJgDQEEwBoCCIA1BBAAawggANYQQACsIYAAWEMAAbCGAAJgDQEEwBoCCIA1BBAAawggANYQQACsIYAABM5teYAHaai9JbXXL3u2ncGhEpU0RpxBvNzgjVcEulxdxR/yP7lfeLZDBkTL6IR/EkBogy4Yup9Solwu27VAD0QAwT8C7/Zz8AMCCN1O3/tSKVpAaIsAgh8QQPCNAEL3M3cJJ4DQFgEEP7WAGANCJwMoIyNDJk2aJAMHDpTBgwfL3LlzpaSkxKtMfX29pKWlSWxsrERERMj8+fOlvLzcq8yVK1dk9uzZEh4ebp5n3bp10tzc3JGqIJDo8GEWDJ0NoLy8PBMup06dkuzsbGlqapKZM2dKXV2dp8yaNWvk4MGDkpWVZcpfu3ZN5s2b5zne0tJiwqexsVFOnjwpe/fulT179sjGjRs7UhUEEMUYEO5FdUJFRYXp3efl5ZntyspKFRISorKysjxlLl68aMrk5+eb7cOHDyun06nKyso8ZTIzM1VkZKRqaGho1/etqqoyz6nX6Hlu/rtQFXy+1LMUfrlK1d3803a14EftfY92agyoqqrKrGNiYsy6sLDQtIpSUlI8ZUaMGCFJSUmSn59vtvV6zJgxEhcX5ymTmpoq1dXVUlxc7PP7NDQ0mON3LwgkiuuA4NNDB5DL5ZLVq1fL9OnTZfTo0WZfWVmZhIaGSnR0tFdZHTb6mLvM3eHjPu4+dq+xp6ioKM+SmJj4sNWGHzgcjrbXAbkY40MXBpAeCzp//rzs379fult6erppbbmX0tLSbv+eeHihEbHiDOnn2XY11UtDzS2rdULP9FCfDlyxYoUcOnRITpw4IUOGDPHsj4+PN4PLlZWVXq0gPQumj7nLFBQUeD2fe5bMXaa1sLAwsyAwOIKCxOFo9buNQWh0tgWkm9I6fA4cOCC5ubkybNgwr+MTJkyQkJAQycnJ8ezT0/R62j05Odls6/W5c+ekoqLCU0bPqEVGRsqoUaM6Uh30UCZ8WnXDgE63gHS3a9++ffLdd9+Za4HcYzZ6XKZ///5mvWTJElm7dq0ZmNahsnLlShM6U6dONWX1tL0OmoULF8q2bdvMc6xfv948N62c3hNAxA+6PIAyMzPN+plnnvHav3v3bnn99dfN19u3bxen02kuQNSzV3qGa9euXZ6yQUFBpvu2fPlyE0wDBgyQRYsWyZYtWzpSFfRktIDQTg49Fy8BRk/D69aWHpDWrSz0LA01N+TCf2VIc32NZ98/UpZJzD8mWq0Xet57lM+CoevRAkI7EUDocowBob0IIHTPhYi0gNAOBBC6Hl0wtBMBhC7390WIBBAejABC13M42nwejD9KBl8IIHS5tuHz91X0QGsEEPyC+4LBFwIIfsFfRIQvBBD8w9ViuwbogQgg+AVdMPhCAMEvlKIFhLYIIPgFLSD4QgDBLxiEhi8EEPxCMQgNHwgg+AddMPhAAMEvGISGLwQQukHbP8fhauG+YGiLAEK33JanX5T3zSfv/O81a/VBz0UAoRs4xBkU4rVH0QKCDwQQukfrGxMCPvAqQff8PSAnLy08GK8SdDk9/Nzm1syAD7xK0C1oAaHL74wKuDU1NUldXd09P3bR2OQ96Nzc3GxuUncv/fr1Mwv6FgIIDyUnJ0feeOMNn8f0JUDLXxgtKU8mefb9/PPPsiXtk3s+3zvvvCOrV6/ulrqi5yKA8FDu3LkjV69evWcAVdX8p1ypHyVljcPkkeByqbvz3/cs776VL/qeDnXUMzMzZezYseZez3pJTk6WI0eOeI7X19dLWlqaxMbGSkREhMyfP1/Ky8u9nuPKlSsye/ZsCQ8Pl8GDB8u6detM8xy9iBK5cuefcrEuWW41/Yf8+86Tcvk294VHJwNoyJAhsnXrViksLJQzZ87Is88+Ky+++KIUFxeb42vWrJGDBw9KVlaW5OXlybVr12TevHmex7e0tJjwaWxslJMnT8revXtlz549snHjxo5UAz2cvv9FddNAURL0/3scUtsSbblWCPgu2Jw5c7y2P/roI9MqOnXqlAmnL774Qvbt22eCSdu9e7eMHDnSHJ86dar88MMPcuHCBfnxxx8lLi5Oxo8fLx988IG8++678v7770toaGjX/nSwZlDwHxLmrJMGV7gEO5okIey3Dt/KB73fQ48B6daMbunomRDdFdOtIj0zkpKS4ikzYsQISUpKkvz8fBNAej1mzBgTPm6pqamyfPly04p68sknO1SHS5cuma4e/O/PP/+87/HiSwVSU7tFbjUlyMDgG1Jfdfm+5SsqKswvJ/QOtbW13RNA586dM4Gjx3v0m//AgQMyatQoKSoqMi2Y6GjvprYOm7KyMvO1Xt8dPu7j7mP30tDQYJbWA5Z6WpfxIzvuNQXvVlhyzSztpV9PlZWVXVAzBMLr46ED6IknnjBho9/833zzjSxatMiM93SnjIwM2bx5c5v9U6ZMMYPh8L/WkwudlZiYKNOmTevS54Q97Z3V7PDlqrqV8/jjj8uECRNMMIwbN04+/fRTiY+PN4PLrX+L6ReqPqbpdesXrnvbXcaX9PR0E3jupbS0tKPVBtADdfp6eZfLZbpHOpBCQkLMBWpuJSUlZtpdd9k0vdZdON3fd8vOzjatGN2Nu5ewsDDP1L97ARD4OtQF0y2RWbNmmYHlmpoaM+N1/Phx+f777yUqKkqWLFkia9eulZiYGBMSK1euNKGjB6C1mTNnmqBZuHChbNu2zYz7rF+/3lw7pEMGQN/SoQDSLZfXXntNrl+/bgJHX5Sow+e5554zx7dv3y5Op9NcgKhbRXqGa9euXZ7HBwUFyaFDh8yslw6mAQMGmDGkLVu2dP1Phm6lW7td2RLlc2B9k0Mppa8bC7gBLh2AejyI7pgdt2/flps3b3bZ8+n/R/1/it6hve9RPguGh6I/SqMXoDP4oy0ArCGAAFhDAAGwhgACYA0BBMAaAgiANQQQAGsIIADWEEAArCGAAFhDAAGwhgACYA0BBMAaAgiANQQQAGsIIADWEEAArCGAAFhDAAGwhgACYA0BBMAaAgiANQQQAGsIIADWEEAArCGAAFhDAAGwhgACYA0BBMAaAgiANcESgJRSZl1dXW27KgB8cL833e/VXhVAN2/eNOvExETbVQFwHzU1NRIVFdW7AigmJsasr1y5ct8fDm1/K+nQLi0tlcjISNvVCQics4ejWz46fBISEu5bLiADyOn8e+hKhw8vio7T54zz1jGcs45rT+OAQWgA1hBAAKwJyAAKCwuTTZs2mTXaj/PWcZyz7uVQD5onA4BuEpAtIAC9AwEEwBoCCIA1BBAAawIygHbu3ClDhw6Vfv36yZQpU6SgoED6qoyMDJk0aZIMHDhQBg8eLHPnzpWSkhKvMvX19ZKWliaxsbESEREh8+fPl/Lycq8y+qry2bNnS3h4uHmedevWSXNzs/QFW7duFYfDIatXr/bs45z5iQow+/fvV6GhoerLL79UxcXFaunSpSo6OlqVl5ervig1NVXt3r1bnT9/XhUVFakXXnhBJSUlqdraWk+ZN998UyUmJqqcnBx15swZNXXqVDVt2jTP8ebmZjV69GiVkpKifv31V3X48GE1aNAglZ6ernq7goICNXToUDV27Fi1atUqz37OmX8EXABNnjxZpaWlebZbWlpUQkKCysjIsFqvnqKiokJfVqHy8vLMdmVlpQoJCVFZWVmeMhcvXjRl8vPzzbZ+8zidTlVWVuYpk5mZqSIjI1VDQ4PqrWpqatTw4cNVdna2evrppz0BxDnzn4DqgjU2NkphYaGkpKR4fS5Mb+fn51utW09RVVXl9YFdfb6ampq8ztmIESMkKSnJc870esyYMRIXF+cpk5qaaj6IWVxcLL2V7mLpLtTd50bjnPlPQH0Y9caNG9LS0uL1n67p7UuXLklf53K5zDjG9OnTZfTo0WZfWVmZhIaGSnR0dJtzpo+5y/g6p+5jvdH+/fvl7Nmzcvr06TbHOGf+E1ABhAf/Rj9//rz89NNPtqvSo+k/rbFq1SrJzs42ExmwJ6C6YIMGDZKgoKA2sxF6Oz4+XvqyFStWyKFDh+TYsWMyZMgQz359XnTXtbKy8p7nTK99nVP3sd5Gd7EqKirkqaeekuDgYLPk5eXJjh07zNe6JcM584+ACiDdLJ4wYYLk5OR4dTv0dnJysvRFeiJBh8+BAwckNzdXhg0b5nVcn6+QkBCvc6an6fUUsvuc6fW5c+fMm9JNtw70378ZNWqU9DYzZswwP29RUZFnmThxoixYsMDzNefMT1QATsOHhYWpPXv2qAsXLqhly5aZafi7ZyP6kuXLl6uoqCh1/Phxdf36dc9y+/ZtryllPTWfm5trppSTk5PN0npKeebMmWYq/+jRo+rRRx/tU1PKd8+CaZwz/wi4ANI+++wz8+LQ1wPpaflTp06pvkr/DvG16GuD3O7cuaPeeust9cgjj6jw8HD10ksvmZC62x9//KFmzZql+vfvb65nefvtt1VTU5PqqwHEOfMP/hwHAGsCagwIQO9CAAGwhgACYA0BBMAaAgiANQQQAGsIIADWEEAArCGAAFhDAAGwhgACYA0BBEBs+T9EhJNKldoCywAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model 得分： 200.0\n"
     ]
    }
   ],
   "source": [
    "score = play_with_model(best_model, show=True)[-1]\n",
    "print(\"Best model 得分：\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
