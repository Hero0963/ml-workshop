{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52226b7",
   "metadata": {},
   "source": [
    "target_entropy = math.log(action_dim)\n",
    "\n",
    "loss_alpha = -(alpha_log * (entropy - target_entropy)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e753264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b711225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5516, 0.4484],\n",
       "        [0.5231, 0.4769]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_action = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model_action(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141e40c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2492,  0.0096],\n",
       "        [-0.0720, -0.1909]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_value1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value1_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value2_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value1_next.load_state_dict(model_value1.state_dict())\n",
    "model_value2_next.load_state_dict(model_value2.state_dict())\n",
    "\n",
    "model_value1(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "944242fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\it_project\\github_sync\\ml-workshop\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    data = []\n",
    "    reward_sum = 0\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    while not over:\n",
    "        prob = model_action(torch.FloatTensor(state).reshape(1, 4))[0].tolist()\n",
    "        action = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        next_state, reward, over = env.step(action)\n",
    "\n",
    "        data.append((state, action, reward, next_state, over))\n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    return data, reward_sum\n",
    "\n",
    "\n",
    "play()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9706a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_62452\\3106662131.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(207,\n",
       " (array([ 0.04721738, -0.02451774,  0.01656285, -0.04620375], dtype=float32),\n",
       "  0,\n",
       "  1.0,\n",
       "  array([ 0.04672703, -0.21987323,  0.01563878,  0.25165853], dtype=float32),\n",
       "  False))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据池\n",
    "class Pool:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pool = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pool)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.pool[i]\n",
    "\n",
    "    #更新动作池\n",
    "    def update(self):\n",
    "        #每次更新不少于N条新数据\n",
    "        old_len = len(self.pool)\n",
    "        while len(self.pool) - old_len < 200:\n",
    "            self.pool.extend(play()[0])\n",
    "\n",
    "        #只保留最新的N条数据\n",
    "        self.pool = self.pool[-2_0000:]\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def sample(self):\n",
    "        data = random.sample(self.pool, 64)\n",
    "\n",
    "        state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n",
    "        action = torch.LongTensor([i[1] for i in data]).reshape(-1, 1)\n",
    "        reward = torch.FloatTensor([i[2] for i in data]).reshape(-1, 1)\n",
    "        next_state = torch.FloatTensor([i[3] for i in data]).reshape(-1, 4)\n",
    "        over = torch.LongTensor([i[4] for i in data]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "pool = Pool()\n",
    "pool.update()\n",
    "state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "len(pool), pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88adf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_log = torch.nn.Parameter(torch.FloatTensor([-1.0]))\n",
    "\n",
    "optimizer_alpha = torch.optim.Adam([alpha_log], lr=1e-4)\n",
    "optimizer_action = torch.optim.Adam(model_action.parameters(), lr=2e-4)\n",
    "optimizer_value1 = torch.optim.Adam(model_value1.parameters(), lr=2e-3)\n",
    "optimizer_value2 = torch.optim.Adam(model_value2.parameters(), lr=2e-3)\n",
    "\n",
    "\n",
    "def soft_update(_from, _to):\n",
    "    for _from, _to in zip(_from.parameters(), _to.parameters()):\n",
    "        value = _to.data * 0.995 + _from.data * 0.005\n",
    "        _to.data.copy_(value)\n",
    "\n",
    "\n",
    "def get_prob_entropy(state):\n",
    "    prob = model_action(torch.FloatTensor(state).reshape(-1, 4))\n",
    "    entropy = prob * (prob + 1e-8).log()\n",
    "    entropy = -entropy.sum(dim=1, keepdim=True)\n",
    "\n",
    "    return prob, entropy\n",
    "\n",
    "\n",
    "def requires_grad(model, value):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9fd2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.396738886833191"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_value(state, action, reward, next_state, over):\n",
    "    requires_grad(model_value1, True)\n",
    "    requires_grad(model_value2, True)\n",
    "    requires_grad(model_action, False)\n",
    "    alpha_log.requires_grad_(False)\n",
    "\n",
    "    #计算target\n",
    "    with torch.no_grad():\n",
    "        #计算动作的熵\n",
    "        prob, entropy = get_prob_entropy(next_state)\n",
    "        target1 = model_value1_next(next_state)\n",
    "        target2 = model_value2_next(next_state)\n",
    "        target = torch.min(target1, target2)\n",
    "\n",
    "    #加权熵,熵越大越好\n",
    "    target = (prob * target).sum(dim=1, keepdim=True)\n",
    "    target = target + alpha_log.exp() * entropy\n",
    "    target = target * 0.98 * (1 - over) + reward\n",
    "\n",
    "    #计算value\n",
    "    value = model_value1(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value1.step()\n",
    "    optimizer_value1.zero_grad()\n",
    "\n",
    "    value = model_value2(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value2.step()\n",
    "    optimizer_value2.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_value(state, action, reward, next_state, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a298674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_action(state):\n",
    "    requires_grad(model_value1, False)\n",
    "    requires_grad(model_value2, False)\n",
    "    requires_grad(model_action, True)\n",
    "    alpha_log.requires_grad_(False)\n",
    "\n",
    "    #计算熵\n",
    "    prob, entropy = get_prob_entropy(state)\n",
    "\n",
    "    #计算value\n",
    "    value1 = model_value1(state)\n",
    "    value2 = model_value2(state)\n",
    "    value = torch.min(value1, value2)\n",
    "\n",
    "    #求期望求和\n",
    "    value = (prob * value).sum(dim=1, keepdim=True)\n",
    "\n",
    "    #加权熵\n",
    "    loss = -(value + alpha_log.exp() * entropy).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_action.step()\n",
    "    optimizer_action.zero_grad()\n",
    "\n",
    "    return loss.item(), entropy.detach()\n",
    "\n",
    "\n",
    "_, entropy = train_action(state)\n",
    "\n",
    "entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6810623c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003297211602330208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_alpha(entropy):\n",
    "    import math\n",
    "\n",
    "    requires_grad(model_value1, False)\n",
    "    requires_grad(model_value2, False)\n",
    "    requires_grad(model_action, False)\n",
    "    alpha_log.requires_grad_(True)\n",
    "\n",
    "    target_entropy = math.log(2)\n",
    "    loss_alpha = -(alpha_log * (entropy - target_entropy)).mean()\n",
    "\n",
    "    optimizer_alpha.zero_grad()\n",
    "    loss_alpha.backward()\n",
    "    optimizer_alpha.step()\n",
    "\n",
    "    return loss_alpha.item()\n",
    "\n",
    "\n",
    "train_alpha(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3515a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 419 0.2623108923435211 149.6\n",
      "10 3379 0.03382936865091324 154.95\n",
      "20 6120 0.004499976057559252 199.9\n",
      "30 8630 0.0006091507384553552 185.55\n",
      "40 11004 8.240409806603566e-05 153.75\n",
      "50 13004 1.1149609235872049e-05 200.0\n",
      "60 15004 1.5142057918637875e-06 200.0\n",
      "70 17004 2.0575832593294763e-07 198.85\n",
      "80 19372 2.7863016782703198e-08 200.0\n",
      "90 20000 3.7736911373542625e-09 200.0\n",
      "100 20000 5.1096399333872e-10 200.0\n",
      "110 20000 6.932207585741423e-11 200.0\n",
      "120 20000 9.39366553293075e-12 172.45\n",
      "130 20000 1.2723180798854261e-12 200.0\n",
      "140 20000 1.719673259044721e-13 200.0\n",
      "150 20000 2.3275555677162822e-14 200.0\n",
      "160 20000 3.1751578481660795e-15 200.0\n",
      "170 20000 4.345655949076089e-16 200.0\n",
      "180 20000 5.93948700863127e-17 200.0\n",
      "190 20000 8.112802159462884e-18 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model_action.train()\n",
    "    model_value1.train()\n",
    "    model_value2.train()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(200):\n",
    "        #更新N条数据\n",
    "        pool.update()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(2000):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "            #训练\n",
    "            train_value(state, action, reward, next_state, over)\n",
    "            _, entropy = train_action(state)\n",
    "            soft_update(model_value1, model_value1_next)\n",
    "            soft_update(model_value2, model_value2_next)\n",
    "            train_alpha(entropy)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, len(pool), alpha_log.exp().item(), test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f219936d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "195.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
