{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f69c1c9",
   "metadata": {},
   "source": [
    "最大化动作的熵,增强模型的稳定性\n",
    "\n",
    "Q(state,action) + alpha * 熵[Q(static,*)]\n",
    "\n",
    "训练过程中alpha应该递减.\n",
    "\n",
    "为了缓解自举,会用两个value模型评估Q函数,取其中小的值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bae8e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3463aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4700, 0.5300],\n",
       "        [0.4458, 0.5542]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_action = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model_action(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef79c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0325, -0.0036],\n",
       "        [ 0.0379,  0.0281]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_value1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value1_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value2_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value1_next.load_state_dict(model_value1.state_dict())\n",
    "model_value2_next.load_state_dict(model_value2.state_dict())\n",
    "\n",
    "model_value1(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1c5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\it_project\\github_sync\\ml-workshop\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    data = []\n",
    "    reward_sum = 0\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    while not over:\n",
    "        prob = model_action(torch.FloatTensor(state).reshape(1, 4))[0].tolist()\n",
    "        action = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        next_state, reward, over = env.step(action)\n",
    "\n",
    "        data.append((state, action, reward, next_state, over))\n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    return data, reward_sum\n",
    "\n",
    "\n",
    "play()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c4fb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_59152\\3891364554.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202,\n",
       " (array([ 0.03273823, -0.01216186, -0.04639029,  0.04894773], dtype=float32),\n",
       "  0,\n",
       "  1.0,\n",
       "  array([ 0.03249499, -0.20658898, -0.04541133,  0.32664078], dtype=float32),\n",
       "  False))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据池\n",
    "class Pool:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pool = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pool)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.pool[i]\n",
    "\n",
    "    #更新动作池\n",
    "    def update(self):\n",
    "        #每次更新不少于N条新数据\n",
    "        old_len = len(self.pool)\n",
    "        while len(pool) - old_len < 200:\n",
    "            self.pool.extend(play()[0])\n",
    "\n",
    "        #只保留最新的N条数据\n",
    "        self.pool = self.pool[-2_0000:]\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def sample(self):\n",
    "        data = random.sample(self.pool, 64)\n",
    "\n",
    "        state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n",
    "        action = torch.LongTensor([i[1] for i in data]).reshape(-1, 1)\n",
    "        reward = torch.FloatTensor([i[2] for i in data]).reshape(-1, 1)\n",
    "        next_state = torch.FloatTensor([i[3] for i in data]).reshape(-1, 4)\n",
    "        over = torch.LongTensor([i[4] for i in data]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "pool = Pool()\n",
    "pool.update()\n",
    "state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "len(pool), pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014f22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_action = torch.optim.Adam(model_action.parameters(), lr=2e-4)\n",
    "optimizer_value1 = torch.optim.Adam(model_value1.parameters(), lr=2e-3)\n",
    "optimizer_value2 = torch.optim.Adam(model_value2.parameters(), lr=2e-3)\n",
    "\n",
    "\n",
    "def soft_update(_from, _to):\n",
    "    for _from, _to in zip(_from.parameters(), _to.parameters()):\n",
    "        value = _to.data * 0.995 + _from.data * 0.005\n",
    "        _to.data.copy_(value)\n",
    "\n",
    "\n",
    "def get_prob_entropy(state):\n",
    "    prob = model_action(torch.FloatTensor(state).reshape(-1, 4))\n",
    "    entropy = prob * (prob + 1e-8).log()\n",
    "    entropy = -entropy.sum(dim=1, keepdim=True)\n",
    "\n",
    "    return prob, entropy\n",
    "\n",
    "\n",
    "def requires_grad(model, value):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(value)\n",
    "\n",
    "\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6f34f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6378400325775146"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_value(state, action, reward, next_state, over):\n",
    "    requires_grad(model_value1, True)\n",
    "    requires_grad(model_value2, True)\n",
    "    requires_grad(model_action, False)\n",
    "\n",
    "    #计算target\n",
    "    with torch.no_grad():\n",
    "        #计算动作的熵\n",
    "        prob, entropy = get_prob_entropy(next_state)\n",
    "        target1 = model_value1_next(next_state)\n",
    "        target2 = model_value2_next(next_state)\n",
    "        target = torch.min(target1, target2)\n",
    "\n",
    "    #加权熵,熵越大越好\n",
    "    target = (prob * target).sum(dim=1, keepdim=True)\n",
    "    target = target + alpha * entropy\n",
    "    target = target * 0.98 * (1 - over) + reward\n",
    "\n",
    "    #计算value\n",
    "    value = model_value1(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value1.step()\n",
    "    optimizer_value1.zero_grad()\n",
    "\n",
    "    value = model_value2(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value2.step()\n",
    "    optimizer_value2.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_value(state, action, reward, next_state, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7328c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7007997632026672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_action(state):\n",
    "    requires_grad(model_value1, False)\n",
    "    requires_grad(model_value2, False)\n",
    "    requires_grad(model_action, True)\n",
    "\n",
    "    #计算熵\n",
    "    prob, entropy = get_prob_entropy(state)\n",
    "\n",
    "    #计算value\n",
    "    value1 = model_value1(state)\n",
    "    value2 = model_value2(state)\n",
    "    value = torch.min(value1, value2)\n",
    "\n",
    "    #求期望求和\n",
    "    value = (prob * value).sum(dim=1, keepdim=True)\n",
    "\n",
    "    #加权熵\n",
    "    loss = -(value + alpha * entropy).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_action.step()\n",
    "    optimizer_action.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de749e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 441 0.95 76.9\n",
      "10 2795 0.5688000922764596 105.35\n",
      "20 4985 0.34056162628811465 200.0\n",
      "30 7151 0.20390682574579033 197.5\n",
      "40 9151 0.12208654873684793 199.3\n",
      "50 11274 0.07309772651287748 200.0\n",
      "60 13274 0.04376630903760433 161.1\n",
      "70 15548 0.02620450591493621 200.0\n",
      "80 17548 0.015689605665762895 200.0\n",
      "90 19548 0.009393946474176 199.25\n",
      "100 20000 0.0056245027593172965 185.55\n",
      "110 20000 0.003367597566851453 200.0\n",
      "120 20000 0.0020163050597632503 200.0\n",
      "130 20000 0.0012072363200535043 200.0\n",
      "140 20000 0.0007228169792062388 200.0\n",
      "150 20000 0.0004327772257594741 200.0\n",
      "160 20000 0.00025911971152330434 199.5\n",
      "170 20000 0.00015514454297379488 200.0\n",
      "180 20000 9.289076879966704e-05 200.0\n",
      "190 20000 5.561713459461251e-05 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    global alpha\n",
    "    model_action.train()\n",
    "    model_value1.train()\n",
    "    model_value2.train()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(200):\n",
    "        #更新N条数据\n",
    "        pool.update()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(2000):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "            #训练\n",
    "            train_value(state, action, reward, next_state, over)\n",
    "            train_action(state)\n",
    "            soft_update(model_value1, model_value1_next)\n",
    "            soft_update(model_value2, model_value2_next)\n",
    "\n",
    "        alpha *= 0.95\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, len(pool), alpha, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871da2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "188.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
