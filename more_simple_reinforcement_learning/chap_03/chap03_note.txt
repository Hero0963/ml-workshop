ref = https://www.bilibili.com/video/BV1FZZ4YwE84

# 策略梯度
回顧：ＱLearning, SARSA, DQN 基於價值
從不好的狀態移動到好的狀態，並採取好的動作
核心 = 優化 Q Table

now: 基於策略做決策
state -> model -> p(action) 
output= 採取某個動作的機率

# 策略迭代 
goal: 找出最大收益的策略
修改做決策的概率


t 時刻: S_t, A_t, R_t 
t + 1 時刻: S_{t + 1}, A_{t + 1}, R_{t + 1} 
t + 2 時刻: S_{t + 2}, A_{t + 2}, R_{t + 2} 

U_t = R_t + gma R_{t + 1} + gma^2 R_{t+2} + ... + gma^{n - t} R_n
Q(s_t, a_t) = E[U_t | S_t=s_t, A_t=a_t]





